## [system]:

```md
Given files:
<file>
<path>src/multi-file-edit/v1/test-helpers.ts</path>
<content>
import \* as vscode from 'vscode'
import { applyResolvedChangesWhileShowingTheEditor } from '../applyResolvedChange'
import { Change, LlmGeneratedPatchXmlV1 } from './types'
import { makeToResolvedChangesTransformer } from './resolveTargetRange'
import { SessionDocumentManager } from 'document-helpers/document-manager'
import { findSingleFileMatchingPartialPath } from 'helpers/vscode'

export async function resolveAndApplyChangesToSingleFile(
changes: Change[],
editor: vscode.TextEditor,
) {
const sessionDocumentManager = new SessionDocumentManager()
await sessionDocumentManager.addDocuments('test', [editor.document.uri])

const resolver = makeToResolvedChangesTransformer(sessionDocumentManager)
const resolvedChanges = await resolver({
changes: changes.map((change) => ({
change,
isStreamFinilized: true,
filePathRelativeToWorkspace: vscode.workspace.asRelativePath(
editor.document.uri,
),
})),

    // Doesn't matter what we put here, plan is only for informational purposes
    plan: [],
    isStreamFinalizedUnused: false,

})

return Promise.all(
resolvedChanges.map(async (resolvedChange) => {
return await applyResolvedChangesWhileShowingTheEditor(resolvedChange)
}),
)
}

export async function resolveAndApplyChangesToMultipleFiles(
patch: LlmGeneratedPatchXmlV1,
) {
const documentUris = await Promise.all(
patch.changes.map((fileChange) =>
findSingleFileMatchingPartialPath(
fileChange.filePathRelativeToWorkspace!,
).then((x) => x!),
),
)
const sessionDocumentManager = new SessionDocumentManager()
await sessionDocumentManager.addDocuments('test', documentUris)
const resolvedChanges = await makeToResolvedChangesTransformer(
sessionDocumentManager,
)(patch)

// Need to apply serially to hold the application assumption that only a single editor is open at the same time
for (const resolvedChange of resolvedChanges)
await applyResolvedChangesWhileShowingTheEditor(resolvedChange)
}

export const makeTemporaryFileWriterAndOpener = (temporaryFileName: string) => {
const temporaryFileUri = vscode.Uri.joinPath(
vscode.workspace.workspaceFolders![0].uri,
temporaryFileName,
)
// Writes content to a temporary file and opens it in an editor
return async (content: string) => {
await vscode.workspace.fs.writeFile(
temporaryFileUri,
new TextEncoder().encode(content),
)
// TODO: This is a hack to make sure the file is saved to disk before we read it
await new Promise((resolve) => setTimeout(resolve, 200))
const document = await vscode.workspace.openTextDocument(temporaryFileUri)
const editor = await vscode.window.showTextDocument(document)
return editor
}
}

export async function openExistingFile(relativeFilePath: string) {
const fileUri = vscode.Uri.joinPath(
vscode.workspace.workspaceFolders![0].uri,
relativeFilePath,
)
const document = await vscode.workspace.openTextDocument(fileUri)
const editor = await vscode.window.showTextDocument(document)
return editor
}

</content>
</file>
<file>
<path>src/multi-file-edit/v1/index.ts</path>
<content>
import * as vscode from 'vscode'

import {
FileContext,
fileContextSystemMessage,
} from 'document-helpers/file-context'
import { OpenAiMessage, streamLlm } from 'helpers/openai'
import { from } from 'ix/asynciterable'

import { startInteractiveMultiFileApplication } from 'multi-file-edit/applyResolvedChange'
import { parsePartialMultiFileEdit } from './parse'
import { makeToResolvedChangesTransformer } from './resolveTargetRange'
import { multiFileEditV1FormatSystemMessage } from './prompt'
import { SessionContext } from 'session'
import { queueAnAppendToDocument } from 'helpers/vscode'

import { map as mapAsync } from 'ix/asynciterable/operators'

export async function startMultiFileEditing(
taskPrompt: string,
breadIdentifier: string,
sessionContext: SessionContext,
) {
const outputFormatMessage =
multiFileEditV1FormatSystemMessage(breadIdentifier)

const fileContexts = sessionContext.documentManager.getFileContexts()
const fileContextMessage = fileContextSystemMessage(fileContexts)

const userTaskMessage: OpenAiMessage = {
role: 'user',
content: `Your task: ${taskPrompt}
You should first output a bullet list plan of action roughly describing each change you want to make. The format should be:

- Plan item one
- Item two

Next you should output changes if nessesary as outlined by the format previously.
`,
}
const messages = [outputFormatMessage, fileContextMessage, userTaskMessage]

const highLevelLogger = (text: string) =>
queueAnAppendToDocument(
sessionContext.markdownHighLevelFeedbackDocument,
text,
)

const lowLevelLogger = (text: string) =>
queueAnAppendToDocument(
sessionContext.markdownLowLevelFeedbackDocument,
text,
)

const logFilePath = (fileContext: FileContext) => {
const path = fileContext.filePathRelativeToWorkspace
// Assumes we are in .bread/sessions
void highLevelLogger(`- [${path}](../../${path})\n`)
}

// Log files that we are submitting as context
void highLevelLogger(`\n# Files submitted:\n`)
for (const fileContext of fileContexts) logFilePath(fileContext)

// Provider pointer to low level log for debugging, it wants a relative to workspace path for some reason
// The document path is .bread/sessions/<id>-<weekday>.raw.md, so we need to go up two levels since the
// markdown file we are outputing to is in .bread/sessions as well
// Likely not windows friendly as it uses /
const relativePath = vscode.workspace.asRelativePath(
sessionContext.markdownLowLevelFeedbackDocument.uri.path,
)
void highLevelLogger(`## [Raw LLM input + response](../../${relativePath})\n`)

const [rawLlmResponseStream, abortController] = await streamLlm(
messages,
lowLevelLogger,
)

// Abort if requested
sessionContext.sessionAbortedEventEmitter.event(() => abortController.abort())

// Design Shortcoming due to multi casting
// Parsing will be performed multiple times for the same payload, see openai.ts
const parsedPatchStream = from(rawLlmResponseStream).pipe(
mapAsync(({ cumulativeResponse, delta }) => {
// Try parsing the xml, even if it's complete it should still be able to apply the diffs
return parsePartialMultiFileEdit(cumulativeResponse)
}),
)

// Split the stream into stream with plan and changes to apply
// Process in parallell
// Currently has an issue where I am unable to log the delta and am forced to wait until an item is fully generated
// Refactor: Parsing should pass deltas or I need to implement local delta generation
async function showPlanAsItBecomesAvailable() {
const planStream = parsedPatchStream.pipe(mapAsync((x) => x.plan))
const loggedPlanIndexWithSuffix = new Set<string>()
void highLevelLogger(`\n# Plan:\n`)
for await (const plan of planStream)
for (const [index, item] of plan.entries()) {
// Find the last suffix that was logged
const latestVersion = `${index}: ${item}`
const lastLoggedVersion = [...loggedPlanIndexWithSuffix]
.filter((x) => x.startsWith(`${index}:`))
.sort((a, b) => b.length - a.length)[0]
// Only logged the delta or the first version including the item separator
if (lastLoggedVersion) {
const delta = latestVersion.slice(lastLoggedVersion.length)
void highLevelLogger(delta)
} else void highLevelLogger(`\n- ${item}`)

        loggedPlanIndexWithSuffix.add(latestVersion)
      }

}

async function startApplication() {
const patchSteam = from(
parsedPatchStream,
makeToResolvedChangesTransformer(sessionContext.documentManager),
)
await startInteractiveMultiFileApplication(patchSteam, sessionContext)
}

await Promise.all([showPlanAsItBecomesAvailable(), startApplication()])
}

</content>
</file>
<file>
<path>src/multi-file-edit/v1/parse.ts</path>
<content>
import {
  extractXmlElementsForTag,
  extractSingleXmlElement,
  trimUpToOneTrailingNewLine,
  trimUpToOneLeadingNewLine,
} from 'xml/parser'
import { TargetRange, LlmGeneratedPatchXmlV1, FileChange } from './types'

/\*
For reference the new format is

@crust Notice the new format of the plan.
Old format relied on having a markdown list of items, which is not very flexible.

Old format:

- Item 1
- Item 2

New format supports any content within the tags:
<plan>
Some free thoughts without particular structure

- Plan item one
  </plan>

<change>
  <path>src/hello-world.ts</path>
  <description>Parametrising function with a name of the thing to be greeted</description>
  <range-to-replace>
function helloWorld() {
    // ${breadIdentifier} pass name to be greeted
    console.log('Hello World');
}
</range-to-replace>
  <!-- The new content to replace the old content between the prefix and suffix -->
  <replacement>
function hello(name: string) {
    console.log(\`Hello \${name}\`);
}
  </replacement>
</change>
*/
export function parsePartialMultiFileEdit(xml: string): LlmGeneratedPatchXmlV1 {
  // Plan is encoded using - as a bullet point for each item
  // Extract the plan before the first change tag
  const planItems: string[] = []
  const [planSection] = xml.split('<change>')
  // Extract plan items using regex,
  // account for first item being in the beginning of the string or on a new line
  const planItemsRegex = /(?:^|\n)- (.*)/g
  let match: RegExpExecArray | null
  while ((match = planItemsRegex.exec(planSection)) !== null)
    planItems.push(match[1])

const fileChangeOutputs = extractXmlElementsForTag(xml, 'change')

// TODO: Drop the new lines right after opening tags range-to-replace and replacement and right before closing tags

const fileChanges = fileChangeOutputs.map((fileChangeOutput): FileChange => {
const path = extractSingleXmlElement(fileChangeOutput.content, 'path')
const description = extractSingleXmlElement(
fileChangeOutput.content,
'description',
)
const oldChunk = extractSingleXmlElement(
fileChangeOutput.content,
'range-to-replace',
)

    // Handle case where old chunk is truncated
    // Warning: Partial truncated printing out will still show
    const oldChunkParts = oldChunk?.content.split('</truncated>') ?? []
    let oldChunkContent: TargetRange

    if (!oldChunk)
      oldChunkContent = {
        type: 'fullContentRange',
        isStreamFinalized: false,
        fullContent: '',
      }
    else if (oldChunkParts.length === 2) {
      // Similar logic to the one embedded in the Xml parsing for regular tags
      const prefixContent = trimUpToOneTrailingNewLine(oldChunkParts[0])
      const suffixContent = trimUpToOneLeadingNewLine(oldChunkParts[1])
      oldChunkContent = {
        type: 'prefixAndSuffixRange',
        prefixContent,
        suffixContent,
        isStreamFinalized: oldChunk.isClosed,
      }
    } else if (oldChunkParts.length === 1)
      oldChunkContent = {
        type: 'fullContentRange',
        fullContent: oldChunk.content,
        isStreamFinalized: oldChunk.isClosed,
      }
    else throw new Error('Unexpected number of old chunk parts')

    const newChunk = extractSingleXmlElement(
      fileChangeOutput.content,
      'replacement',
    )

    // Strange code due to switching the encoding from multiple changes within a single file tag
    // to a more flat xml encoding but keeping the old data structure
    // Ideally we want to group the changes by file, but the hell with it for now
    const singularChangeForAFile = {
      description: description?.content ?? '',
      oldChunk: oldChunkContent,
      newChunk: {
        content: newChunk?.content ?? '',
        isStreamFinalized: newChunk?.isClosed ?? false,
      },
    }

    return {
      filePathRelativeToWorkspace: path?.content,
      change: singularChangeForAFile,
      isStreamFinilized: fileChangeOutput.isClosed,
    }

})

return {
changes: fileChanges,
isStreamFinalizedUnused: false,
plan: planItems,
}
}

</content>
</file>
<file>
<path>src/multi-file-edit/v1/types.ts</path>
<content>
/*
  Created a new interface
  interface Streamed {
    isStreamFinalized: boolean
  }
  I will later extend Change RangeToReplace to be Streamed
  I will also create a custom string container that will be Streamed

I'm delaying this abstraction right now in favor off actually writing code into the files.

Workaround

- I will require old chunk to be fully completed before trying to write to a file,
  this is because we want to know the range and the file we're writing to before we start writing.
- I will also make nu chunk optional that will signal that the old chunk is finally complete
  \*/

export type TargetRange =
| {
type: 'fullContentRange'
isStreamFinalized: boolean
fullContent: string
}
| {
type: 'prefixAndSuffixRange'
isStreamFinalized: boolean
prefixContent: string
suffixContent: string
}

export interface Replacement {
isStreamFinalized: boolean
content: string
}

export interface Change {
description: string
oldChunk: TargetRange
newChunk: Replacement
}

export interface FileChange {
/\*\* If not present - means its streaming.

- We will use this field early to show the file targeted with a change \*/
  filePathRelativeToWorkspace?: string
  change: Change
  isStreamFinilized: boolean
  }

export interface LlmGeneratedPatchXmlV1 {
/\*\*

- @crust
- - I have updated the type to be a string instead of a string array, make changes acordingly across the files\
- to account for this change, including the fixes to address the compilation errors due to this refactor.
- - First You should update the parsing code to support it. Now you should parse the plan using the helper to extract xml elements for a tag <plan>. You should get rid of regex matching in that parsing code.
- - Next update the code where we print out the plan to use the new format.
- Currently we are processing a stream of different versions of the parsed LlmGeneratedPatchXmlV1.
- As the time goes on the stream will have more and more content within the plan. We have a for
- loop that iterates over the plan items - get rid of the for lop but keep the set to keep track of
- last printed plan version. We also don't need to find the matching plan anymore.
- And we don't need the set anymore actually. Replace it with a let lastPlanVersion = ''
  _/
  plan: string
  changes: FileChange[]
  /\*\* Not used now, but it's much easier to add a new field to an object type versus an array _/
  isStreamFinalizedUnused: boolean
  }

export const isChangeFinalized = (change: Change) =>
change.newChunk.isStreamFinalized && change.oldChunk.isStreamFinalized

</content>
</file>
<file>
<path>.crust.md</path>
<content>
This project is a VSCode extension that invokes LLMs to help users edit their code files using natural language.
All the code is in typescript and nothing should have an any type.

</content>
</file>
```

## [user]:

```md
Your task: Fix these problems: File: src/multi-file-edit/v1/test-helpers.ts
Error message: Type 'never[]' is not assignable to type 'string'.
Range:

- Line start 25
- Line end 25
  Related info: The expected type comes from property 'plan' which is declared here on type 'LlmGeneratedPatchXmlV1'

File: src/multi-file-edit/v1/index.ts
Error message: Property 'entries' does not exist on type 'string'.
Range:

- Line start 98
- Line end 98

File: src/multi-file-edit/v1/index.ts
Error message: 'delta' is declared but its value is never read.
Range:

- Line start 83
- Line end 83

File: src/multi-file-edit/v1/index.ts
Error message: Unsafe call of an `any` typed value.
Range:

- Line start 98
- Line end 98

File: src/multi-file-edit/v1/parse.ts
Error message: Type 'string[]' is not assignable to type 'string'.
Range:

- Line start 125
- Line end 125
  Related info: The expected type comes from property 'plan' which is declared here on type 'LlmGeneratedPatchXmlV1'
```

- You should not revert the refactor of plan: string back to string[] to fix the problem
- You should output only 3 ways you can think of fixing the problem
- Keep in mind that when something breaks due to a refactor, you should usually avoid trying to fix the problem right there and think about implications of the refactor and how to fix the problem in a way that will be inline with what the refactor was trying to achieve
